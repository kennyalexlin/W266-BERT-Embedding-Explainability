{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request, json, os, math\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers import (\n",
        "    TFBertForMaskedLM,\n",
        "    PreTrainedTokenizerFast,\n",
        ")\n",
        "\n",
        "from scipy.spatial.distance import cosine"
      ],
      "metadata": {
        "id": "nHT_t2r-M5qF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    import sys\n",
        "\n",
        "    drive.mount('/content/gdrive/')\n",
        "    sys.path.append('/content/gdrive/My Drive/Colab Notebooks')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "from utils import (\n",
        "    get_token_embedding\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5vzgkxGNLtD",
        "outputId": "352ce008-e971-4f73-b2b2-dc5062dd9685"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '/content/gdrive/My Drive/Colab Notebooks/w266_final_proj'\n",
        "\n",
        "TOKENIZER1_PATH = 'birthyear.1990_2009.lowercase_tokenizer'\n",
        "TOKENIZER2_PATH = 'birthyear.1950_1969.lowercase_tokenizer'\n",
        "\n",
        "MODEL1_PATH = f'birthyear.1990_2009.lowercase_64batch_size_1000steps'\n",
        "MODEL2_PATH = f'birthyear.1950_1969.lowercase_64batch_size_1000steps'\n",
        "\n",
        "# path2 to load trained tokenizers from\n",
        "full_tokenizer1_path = os.path.join(DATA_DIR, TOKENIZER1_PATH)\n",
        "full_tokenizer2_path = os.path.join(DATA_DIR, TOKENIZER2_PATH)\n",
        "\n",
        "# path2 to load trained BERT model2 from\n",
        "full_model1_path = os.path.join(DATA_DIR, MODEL1_PATH)\n",
        "full_model2_path = os.path.join(DATA_DIR, MODEL2_PATH)"
      ],
      "metadata": {
        "id": "r-Lo8NEAM0NZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model #1"
      ],
      "metadata": {
        "id": "nI8cf2DpQHFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(full_tokenizer1_path)\n",
        "bert_model = TFBertForMaskedLM.from_pretrained(full_model1_path)\n",
        "\n",
        "embedding_layer = bert_model.bert.embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od2-Vtu8N6zY",
        "outputId": "c98dd8fb-94ac-4545-8397-ae1aa51a9f1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at /content/gdrive/My Drive/Colab Notebooks/w266_final_proj/birthyear.1990_2009.lowercase_64batch_size_1000steps were not used when initializing TFBertForMaskedLM: ['encoder/layer_._8/output/LayerNorm/beta:0', 'encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'encoder/layer_._6/attention/self/key/bias:0', 'encoder/layer_._7/attention/self/key/kernel:0', 'encoder/layer_._0/attention/output/dense/kernel:0', 'encoder/layer_._5/attention/self/query/bias:0', 'encoder/layer_._2/intermediate/dense/kernel:0', 'encoder/layer_._9/output/LayerNorm/gamma:0', 'embeddings/word_embeddings/weight:0', 'embeddings/LayerNorm/beta:0', 'encoder/layer_._5/attention/output/dense/bias:0', 'encoder/layer_._7/attention/self/value/kernel:0', 'encoder/layer_._3/output/LayerNorm/gamma:0', 'predictions/transform/dense/bias:0', 'encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'encoder/layer_._6/attention/output/dense/bias:0', 'encoder/layer_._4/attention/self/query/bias:0', 'encoder/layer_._10/attention/output/LayerNorm/beta:0', 'encoder/layer_._3/attention/self/query/kernel:0', 'encoder/layer_._6/output/LayerNorm/beta:0', 'encoder/layer_._0/attention/self/value/kernel:0', 'encoder/layer_._4/attention/self/value/kernel:0', 'predictions/transform/LayerNorm/gamma:0', 'encoder/layer_._5/intermediate/dense/kernel:0', 'encoder/layer_._9/attention/output/dense/kernel:0', 'encoder/layer_._4/output/dense/bias:0', 'encoder/layer_._1/intermediate/dense/kernel:0', 'encoder/layer_._0/attention/self/key/bias:0', 'encoder/layer_._3/attention/output/dense/kernel:0', 'encoder/layer_._0/attention/self/value/bias:0', 'encoder/layer_._5/intermediate/dense/bias:0', 'encoder/layer_._8/output/dense/kernel:0', 'encoder/layer_._9/intermediate/dense/bias:0', 'encoder/layer_._11/attention/output/LayerNorm/beta:0', 'encoder/layer_._5/output/dense/kernel:0', 'encoder/layer_._8/attention/output/dense/bias:0', 'encoder/layer_._0/output/dense/kernel:0', 'encoder/layer_._0/attention/self/query/bias:0', 'encoder/layer_._10/output/dense/kernel:0', 'encoder/layer_._3/attention/self/key/kernel:0', 'encoder/layer_._9/attention/self/value/kernel:0', 'encoder/layer_._9/attention/self/key/bias:0', 'encoder/layer_._5/attention/self/key/kernel:0', 'encoder/layer_._7/attention/self/query/kernel:0', 'encoder/layer_._0/output/LayerNorm/beta:0', 'encoder/layer_._5/output/LayerNorm/gamma:0', 'encoder/layer_._5/output/LayerNorm/beta:0', 'encoder/layer_._10/attention/self/value/kernel:0', 'encoder/layer_._9/output/LayerNorm/beta:0', 'encoder/layer_._3/attention/self/query/bias:0', 'encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'encoder/layer_._5/attention/self/key/bias:0', 'encoder/layer_._1/output/dense/kernel:0', 'encoder/layer_._8/output/dense/bias:0', 'encoder/layer_._11/output/LayerNorm/beta:0', 'embeddings/token_type_embeddings/embeddings:0', 'encoder/layer_._5/attention/output/dense/kernel:0', 'encoder/layer_._8/attention/self/key/kernel:0', 'encoder/layer_._4/attention/output/dense/kernel:0', 'encoder/layer_._8/intermediate/dense/bias:0', 'encoder/layer_._2/attention/output/dense/kernel:0', 'encoder/layer_._8/attention/self/value/kernel:0', 'encoder/layer_._11/attention/self/query/bias:0', 'encoder/layer_._7/output/LayerNorm/beta:0', 'encoder/layer_._8/attention/self/query/kernel:0', 'encoder/layer_._4/attention/self/query/kernel:0', 'encoder/layer_._11/attention/output/dense/kernel:0', 'encoder/layer_._6/intermediate/dense/kernel:0', 'encoder/layer_._6/attention/self/query/kernel:0', 'encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'encoder/layer_._10/attention/self/query/bias:0', 'encoder/layer_._1/output/LayerNorm/beta:0', 'encoder/layer_._4/output/LayerNorm/beta:0', 'encoder/layer_._11/attention/self/value/bias:0', 'encoder/layer_._2/output/LayerNorm/beta:0', 'encoder/layer_._9/attention/self/key/kernel:0', 'encoder/layer_._1/output/dense/bias:0', 'encoder/layer_._10/attention/output/dense/kernel:0', 'encoder/layer_._3/output/LayerNorm/beta:0', 'encoder/layer_._5/output/dense/bias:0', 'encoder/layer_._2/attention/output/LayerNorm/beta:0', 'encoder/layer_._6/attention/self/value/kernel:0', 'encoder/layer_._6/intermediate/dense/bias:0', 'encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'encoder/layer_._9/intermediate/dense/kernel:0', 'encoder/layer_._0/attention/self/query/kernel:0', 'encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'encoder/layer_._9/attention/output/LayerNorm/beta:0', 'encoder/layer_._7/intermediate/dense/bias:0', 'encoder/layer_._5/attention/self/value/kernel:0', 'encoder/layer_._0/output/dense/bias:0', 'encoder/layer_._2/attention/self/key/kernel:0', 'encoder/layer_._3/output/dense/bias:0', 'encoder/layer_._5/attention/self/value/bias:0', 'encoder/layer_._4/attention/self/value/bias:0', 'encoder/layer_._1/attention/output/dense/kernel:0', 'encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'encoder/layer_._1/intermediate/dense/bias:0', 'encoder/layer_._0/attention/output/dense/bias:0', 'encoder/layer_._11/intermediate/dense/bias:0', 'encoder/layer_._3/output/dense/kernel:0', 'encoder/layer_._6/attention/self/key/kernel:0', 'encoder/layer_._4/intermediate/dense/kernel:0', 'encoder/layer_._2/attention/self/query/bias:0', 'encoder/layer_._2/attention/self/key/bias:0', 'encoder/layer_._7/attention/self/query/bias:0', 'encoder/layer_._4/output/LayerNorm/gamma:0', 'encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'encoder/layer_._9/attention/self/query/kernel:0', 'encoder/layer_._2/attention/self/query/kernel:0', 'encoder/layer_._6/output/dense/bias:0', 'encoder/layer_._7/attention/output/dense/bias:0', 'encoder/layer_._9/output/dense/bias:0', 'embeddings/position_embeddings/embeddings:0', 'encoder/layer_._1/attention/self/key/bias:0', 'encoder/layer_._7/attention/self/key/bias:0', 'encoder/layer_._4/output/dense/kernel:0', 'encoder/layer_._10/attention/self/key/bias:0', 'encoder/layer_._1/attention/output/LayerNorm/beta:0', 'encoder/layer_._7/output/dense/kernel:0', 'encoder/layer_._8/attention/output/dense/kernel:0', 'encoder/layer_._4/attention/output/LayerNorm/beta:0', 'encoder/layer_._0/attention/self/key/kernel:0', 'encoder/layer_._4/attention/output/dense/bias:0', 'encoder/layer_._8/intermediate/dense/kernel:0', 'encoder/layer_._0/attention/output/LayerNorm/beta:0', 'encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'encoder/layer_._1/attention/self/value/bias:0', 'encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'encoder/layer_._1/attention/output/dense/bias:0', 'encoder/layer_._3/attention/self/value/bias:0', 'encoder/layer_._6/attention/self/value/bias:0', 'encoder/layer_._2/output/dense/bias:0', 'encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'encoder/layer_._0/intermediate/dense/bias:0', 'encoder/layer_._3/intermediate/dense/bias:0', 'encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'predictions/transform/dense/kernel:0', 'encoder/layer_._10/output/dense/bias:0', 'encoder/layer_._6/output/dense/kernel:0', 'encoder/layer_._7/attention/self/value/bias:0', 'encoder/layer_._3/attention/self/key/bias:0', 'encoder/layer_._10/output/LayerNorm/beta:0', 'encoder/layer_._7/attention/output/LayerNorm/beta:0', 'encoder/layer_._10/intermediate/dense/kernel:0', 'encoder/layer_._11/attention/self/key/kernel:0', 'encoder/layer_._8/output/LayerNorm/gamma:0', 'encoder/layer_._11/attention/self/value/kernel:0', 'encoder/layer_._9/attention/self/value/bias:0', 'encoder/layer_._10/attention/self/key/kernel:0', 'encoder/layer_._4/intermediate/dense/bias:0', 'encoder/layer_._6/attention/output/dense/kernel:0', 'embeddings/LayerNorm/gamma:0', 'encoder/layer_._7/attention/output/dense/kernel:0', 'encoder/layer_._8/attention/self/key/bias:0', 'encoder/layer_._11/attention/output/dense/bias:0', 'encoder/layer_._9/output/dense/kernel:0', 'encoder/layer_._10/attention/self/value/bias:0', 'encoder/layer_._4/attention/self/key/bias:0', 'encoder/layer_._4/attention/self/key/kernel:0', 'predictions/transform/LayerNorm/beta:0', 'encoder/layer_._0/output/LayerNorm/gamma:0', 'encoder/layer_._0/intermediate/dense/kernel:0', 'encoder/layer_._7/intermediate/dense/kernel:0', 'encoder/layer_._2/output/LayerNorm/gamma:0', 'encoder/layer_._7/output/dense/bias:0', 'encoder/layer_._11/attention/self/key/bias:0', 'encoder/layer_._2/output/dense/kernel:0', 'encoder/layer_._10/output/LayerNorm/gamma:0', 'encoder/layer_._11/output/dense/bias:0', 'encoder/layer_._11/output/LayerNorm/gamma:0', 'encoder/layer_._2/attention/output/dense/bias:0', 'encoder/layer_._6/attention/self/query/bias:0', 'encoder/layer_._1/attention/self/query/kernel:0', 'encoder/layer_._10/attention/output/dense/bias:0', 'encoder/layer_._3/intermediate/dense/kernel:0', 'encoder/layer_._11/attention/self/query/kernel:0', 'encoder/layer_._1/attention/self/query/bias:0', 'encoder/layer_._10/attention/self/query/kernel:0', 'encoder/layer_._2/attention/self/value/kernel:0', 'encoder/layer_._8/attention/self/value/bias:0', 'encoder/layer_._7/output/LayerNorm/gamma:0', 'encoder/layer_._3/attention/output/LayerNorm/beta:0', 'encoder/layer_._2/attention/self/value/bias:0', 'encoder/layer_._1/attention/self/key/kernel:0', 'encoder/layer_._5/attention/self/query/kernel:0', 'encoder/layer_._8/attention/self/query/bias:0', 'encoder/layer_._3/attention/output/dense/bias:0', 'predictions/bias:0', 'encoder/layer_._3/attention/self/value/kernel:0', 'encoder/layer_._11/output/dense/kernel:0', 'encoder/layer_._6/attention/output/LayerNorm/beta:0', 'encoder/layer_._1/attention/self/value/kernel:0', 'encoder/layer_._5/attention/output/LayerNorm/beta:0', 'encoder/layer_._8/attention/output/LayerNorm/beta:0', 'encoder/layer_._9/attention/output/dense/bias:0', 'encoder/layer_._11/intermediate/dense/kernel:0', 'encoder/layer_._9/attention/self/query/bias:0', 'encoder/layer_._1/output/LayerNorm/gamma:0', 'encoder/layer_._10/intermediate/dense/bias:0', 'encoder/layer_._6/output/LayerNorm/gamma:0', 'encoder/layer_._2/intermediate/dense/bias:0']\n",
            "- This IS expected if you are initializing TFBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertForMaskedLM were not initialized from the model checkpoint at /content/gdrive/My Drive/Colab Notebooks/w266_final_proj/birthyear.1990_2009.lowercase_64batch_size_1000steps and are newly initialized: ['bert/encoder/layer_._7/attention/self/value/kernel:0', 'mlm___cls/predictions/transform/dense/bias:0', 'bert/encoder/layer_._7/output/LayerNorm/beta:0', 'bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/attention/self/query/kernel:0', 'bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._1/output/LayerNorm/beta:0', 'bert/encoder/layer_._3/attention/self/key/kernel:0', 'bert/encoder/layer_._5/attention/output/dense/bias:0', 'bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'bert/encoder/layer_._0/attention/self/key/bias:0', 'bert/encoder/layer_._6/attention/self/value/bias:0', 'bert/embeddings/word_embeddings/weight:0', 'bert/encoder/layer_._5/attention/self/value/kernel:0', 'bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._9/attention/self/query/bias:0', 'bert/encoder/layer_._10/attention/self/key/kernel:0', 'bert/encoder/layer_._11/intermediate/dense/bias:0', 'bert/encoder/layer_._6/intermediate/dense/bias:0', 'bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/output/dense/bias:0', 'bert/encoder/layer_._6/attention/self/query/bias:0', 'bert/encoder/layer_._4/attention/self/value/kernel:0', 'bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._7/output/dense/bias:0', 'bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._6/attention/self/key/bias:0', 'bert/encoder/layer_._8/attention/self/value/bias:0', 'bert/encoder/layer_._11/attention/output/dense/bias:0', 'bert/encoder/layer_._2/attention/self/key/bias:0', 'bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'bert/encoder/layer_._3/attention/self/value/bias:0', 'bert/encoder/layer_._9/attention/self/query/kernel:0', 'bert/encoder/layer_._0/attention/self/value/bias:0', 'bert/encoder/layer_._9/attention/self/value/bias:0', 'bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/intermediate/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/value/bias:0', 'mlm___cls/predictions/transform/LayerNorm/beta:0', 'bert/encoder/layer_._4/intermediate/dense/kernel:0', 'bert/encoder/layer_._7/attention/self/key/kernel:0', 'bert/encoder/layer_._0/attention/self/value/kernel:0', 'bert/encoder/layer_._8/attention/self/key/kernel:0', 'bert/encoder/layer_._1/attention/output/dense/bias:0', 'bert/embeddings/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/key/kernel:0', 'bert/encoder/layer_._0/intermediate/dense/bias:0', 'bert/encoder/layer_._4/output/LayerNorm/beta:0', 'bert/encoder/layer_._8/output/LayerNorm/beta:0', 'bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._4/attention/self/key/kernel:0', 'bert/encoder/layer_._10/intermediate/dense/bias:0', 'bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._4/output/dense/kernel:0', 'bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'bert/encoder/layer_._8/attention/self/query/kernel:0', 'bert/encoder/layer_._5/attention/self/query/bias:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/attention/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._9/output/LayerNorm/beta:0', 'bert/encoder/layer_._7/attention/self/key/bias:0', 'bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'bert/embeddings/position_embeddings/weight:0', 'bert/encoder/layer_._8/attention/output/dense/kernel:0', 'bert/encoder/layer_._9/attention/self/key/bias:0', 'bert/encoder/layer_._3/output/dense/kernel:0', 'bert/encoder/layer_._1/intermediate/dense/bias:0', 'bert/encoder/layer_._8/intermediate/dense/bias:0', 'bert/embeddings/LayerNorm/gamma:0', 'bert/encoder/layer_._4/attention/self/value/bias:0', 'bert/encoder/layer_._11/attention/self/query/kernel:0', 'bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/attention/self/query/bias:0', 'bert/encoder/layer_._10/attention/self/key/bias:0', 'bert/encoder/layer_._11/intermediate/dense/kernel:0', 'bert/encoder/layer_._9/intermediate/dense/kernel:0', 'bert/encoder/layer_._3/attention/self/query/bias:0', 'bert/encoder/layer_._6/attention/self/value/kernel:0', 'bert/encoder/layer_._4/output/dense/bias:0', 'bert/encoder/layer_._9/attention/self/key/kernel:0', 'bert/encoder/layer_._8/intermediate/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/query/kernel:0', 'bert/encoder/layer_._2/output/dense/kernel:0', 'bert/encoder/layer_._4/attention/output/dense/bias:0', 'bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._5/output/dense/kernel:0', 'bert/encoder/layer_._6/attention/output/dense/bias:0', 'bert/encoder/layer_._10/output/dense/bias:0', 'bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'bert/encoder/layer_._6/attention/output/dense/kernel:0', 'bert/encoder/layer_._7/attention/output/dense/bias:0', 'bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/output/dense/bias:0', 'bert/encoder/layer_._6/output/dense/bias:0', 'bert/encoder/layer_._1/attention/output/dense/kernel:0', 'bert/encoder/layer_._8/attention/self/key/bias:0', 'bert/encoder/layer_._8/output/dense/bias:0', 'bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'bert/encoder/layer_._7/output/dense/kernel:0', 'bert/encoder/layer_._4/intermediate/dense/bias:0', 'bert/encoder/layer_._9/intermediate/dense/bias:0', 'bert/encoder/layer_._6/attention/self/query/kernel:0', 'bert/encoder/layer_._3/attention/output/dense/kernel:0', 'bert/encoder/layer_._10/attention/self/query/kernel:0', 'bert/encoder/layer_._7/attention/self/value/bias:0', 'bert/encoder/layer_._11/attention/self/query/bias:0', 'bert/encoder/layer_._1/attention/self/key/bias:0', 'bert/encoder/layer_._11/output/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/query/bias:0', 'bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._8/output/dense/kernel:0', 'bert/encoder/layer_._1/attention/self/query/bias:0', 'bert/encoder/layer_._11/attention/self/key/bias:0', 'bert/encoder/layer_._8/attention/self/query/bias:0', 'bert/encoder/layer_._1/attention/self/key/kernel:0', 'bert/encoder/layer_._10/attention/self/value/bias:0', 'bert/embeddings/token_type_embeddings/weight:0', 'bert/encoder/layer_._3/attention/self/key/bias:0', 'bert/encoder/layer_._1/attention/self/value/kernel:0', 'bert/encoder/layer_._3/attention/output/dense/bias:0', 'bert/encoder/layer_._5/output/LayerNorm/beta:0', 'bert/encoder/layer_._6/output/dense/kernel:0', 'bert/encoder/layer_._4/attention/output/dense/kernel:0', 'bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._2/attention/self/value/kernel:0', 'bert/encoder/layer_._5/attention/self/query/kernel:0', 'bert/encoder/layer_._5/attention/output/dense/kernel:0', 'bert/encoder/layer_._9/attention/self/value/kernel:0', 'bert/encoder/layer_._1/output/dense/bias:0', 'bert/encoder/layer_._2/attention/output/dense/kernel:0', 'bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/query/kernel:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._9/attention/output/dense/kernel:0', 'bert/encoder/layer_._7/intermediate/dense/bias:0', 'bert/encoder/layer_._0/output/dense/bias:0', 'bert/encoder/layer_._8/attention/self/value/kernel:0', 'bert/encoder/layer_._10/attention/self/value/kernel:0', 'bert/encoder/layer_._6/intermediate/dense/kernel:0', 'bert/encoder/layer_._7/attention/output/dense/kernel:0', 'bert/encoder/layer_._7/intermediate/dense/kernel:0', 'bert/encoder/layer_._1/attention/self/value/bias:0', 'bert/encoder/layer_._2/attention/self/value/bias:0', 'bert/encoder/layer_._2/intermediate/dense/kernel:0', 'bert/encoder/layer_._0/output/LayerNorm/beta:0', 'bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/intermediate/dense/kernel:0', 'bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'bert/encoder/layer_._3/attention/self/query/kernel:0', 'bert/encoder/layer_._5/output/dense/bias:0', 'bert/encoder/layer_._0/attention/self/query/bias:0', 'bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._2/attention/output/dense/bias:0', 'bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/output/dense/kernel:0', 'bert/encoder/layer_._9/output/dense/kernel:0', 'bert/encoder/layer_._10/attention/output/dense/bias:0', 'mlm___cls/predictions/bias:0', 'bert/encoder/layer_._6/attention/self/key/kernel:0', 'bert/encoder/layer_._1/intermediate/dense/kernel:0', 'bert/encoder/layer_._2/intermediate/dense/bias:0', 'bert/encoder/layer_._3/attention/self/value/kernel:0', 'bert/encoder/layer_._5/intermediate/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/value/kernel:0', 'bert/encoder/layer_._0/output/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/key/bias:0', 'bert/encoder/layer_._1/attention/self/query/kernel:0', 'bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._3/intermediate/dense/kernel:0', 'bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'mlm___cls/predictions/transform/LayerNorm/gamma:0', 'bert/encoder/layer_._0/attention/output/dense/kernel:0', 'bert/encoder/layer_._8/attention/output/dense/bias:0', 'bert/encoder/layer_._2/attention/self/query/bias:0', 'bert/encoder/layer_._5/attention/self/key/kernel:0', 'bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'bert/encoder/layer_._5/intermediate/dense/bias:0', 'bert/encoder/layer_._10/output/LayerNorm/beta:0', 'bert/encoder/layer_._7/attention/self/query/kernel:0', 'bert/encoder/layer_._3/output/LayerNorm/beta:0', 'bert/encoder/layer_._7/attention/self/query/bias:0', 'bert/encoder/layer_._10/output/dense/kernel:0', 'bert/encoder/layer_._1/output/dense/kernel:0', 'bert/encoder/layer_._11/output/dense/bias:0', 'bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._2/attention/self/key/kernel:0', 'mlm___cls/predictions/transform/dense/kernel:0', 'bert/encoder/layer_._5/attention/self/value/bias:0', 'bert/encoder/layer_._11/attention/self/key/kernel:0', 'bert/encoder/layer_._9/output/dense/bias:0', 'bert/encoder/layer_._3/output/dense/bias:0', 'bert/encoder/layer_._5/attention/self/key/bias:0', 'bert/encoder/layer_._11/output/LayerNorm/beta:0', 'bert/encoder/layer_._3/intermediate/dense/bias:0', 'bert/encoder/layer_._9/attention/output/dense/bias:0', 'bert/encoder/layer_._6/output/LayerNorm/beta:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = tokenizer.get_vocab()\n",
        "vocab_ids = list(vocab.values())\n",
        "\n",
        "embeddings = [embedding_layer(tf.constant([[token_id]])) for token_id in vocab_ids]"
      ],
      "metadata": {
        "id": "vDoHCPJoUPe9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_k_nearest_neighbors(\n",
        "    token,\n",
        "    embeddings,\n",
        "    tokenizer,\n",
        "    embedding_layer,\n",
        "    k=10):\n",
        "    # get the top k nearest neighbors for a given token\n",
        "\n",
        "    vocab_tokens = list(tokenizer.get_vocab().keys())\n",
        "\n",
        "    token_embedding = get_token_embedding(\n",
        "        tokenizer,\n",
        "        embedding_layer,\n",
        "        token\n",
        "    )\n",
        "\n",
        "    dists = []\n",
        "    ignore = tokenizer.all_special_tokens + [token]\n",
        "    for idx, embedding in enumerate(embeddings):\n",
        "        if vocab_tokens[idx] in ignore:\n",
        "            dists.append(10) # don't consider when getting nearest neighbors\n",
        "        else:\n",
        "            dists.append(cosine(token_embedding, embedding))\n",
        "\n",
        "    sort_idx = np.array(dists).argsort()\n",
        "    sorted_dists = np.array(dists)[sort_idx]\n",
        "    sorted_tokens = np.array(vocab_tokens)[sort_idx]\n",
        "\n",
        "    return sorted_tokens[:k], sorted_dists[:k]"
      ],
      "metadata": {
        "id": "_lj_aF-ETcRw"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_k, top_k_dists = get_k_nearest_neighbors(\n",
        "    'dog',\n",
        "    embeddings,\n",
        "    tokenizer,\n",
        "    embedding_layer\n",
        ")\n",
        "top_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZyvR8JwY4ip",
        "outputId": "a3aacbfc-d94c-40af-b193-cf05c6f9bdd3"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['gha', 'dragging', 'hospital', 'vital', 'bowler', 'obit',\n",
              "       'prosecut', 'vlog', 'sig', 'ann'], dtype='<U34')"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    }
  ]
}