{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO0UIXc4zb1EWCPz09rVBOX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import urllib.request, json, os, math\n","import tensorflow as tf\n","\n","from transformers import (\n","    TFBertForMaskedLM,\n","    PreTrainedTokenizerFast,\n",")\n","\n","from scipy.spatial.distance import cosine"],"metadata":{"id":"nHT_t2r-M5qF","executionInfo":{"status":"ok","timestamp":1722222371331,"user_tz":300,"elapsed":13873,"user":{"displayName":"Kenneth Lin","userId":"01443000796591967739"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["try:\n","    from google.colab import drive\n","    import sys\n","\n","    drive.mount('/content/gdrive/')\n","    sys.path.append('/content/gdrive/My Drive/Colab Notebooks')\n","except:\n","    pass\n","\n","from utils import (\n","    get_token_embedding,\n","    get_k_nearest_neighbors,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5vzgkxGNLtD","executionInfo":{"status":"ok","timestamp":1722222372679,"user_tz":300,"elapsed":1368,"user":{"displayName":"Kenneth Lin","userId":"01443000796591967739"}},"outputId":"c4f9b165-017a-4673-d01a-9b4d292f4b07"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["PROJECT_DIR = '/content/gdrive/My Drive/Colab Notebooks/w266_final_proj'\n","\n","TOKENIZER1_PATH = 'birthyear.1990_2009.lowercase_tokenizer'\n","TOKENIZER2_PATH = 'birthyear.1950_1969.lowercase_tokenizer'\n","\n","MODEL1_PATH = f'birthyear.1990_2009.lowercase_64batch_size_1000steps'\n","MODEL2_PATH = f'birthyear.1950_1969.lowercase_64batch_size_1000steps'\n","\n","# path to load trained tokenizers from\n","full_tokenizer1_path = os.path.join(PROJECT_DIR, TOKENIZER1_PATH)\n","full_tokenizer2_path = os.path.join(PROJECT_DIR, TOKENIZER2_PATH)\n","\n","# path to load trained BERT model2 from\n","full_model1_path = os.path.join(PROJECT_DIR, MODEL1_PATH)\n","full_model2_path = os.path.join(PROJECT_DIR, MODEL2_PATH)"],"metadata":{"id":"r-Lo8NEAM0NZ","executionInfo":{"status":"ok","timestamp":1722222379158,"user_tz":300,"elapsed":334,"user":{"displayName":"Kenneth Lin","userId":"01443000796591967739"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Load Models"],"metadata":{"id":"nI8cf2DpQHFY"}},{"cell_type":"code","source":["tokenizer1 = PreTrainedTokenizerFast.from_pretrained(full_tokenizer1_path)\n","tokenizer2 = PreTrainedTokenizerFast.from_pretrained(full_tokenizer2_path)\n","\n","bert_model1 = TFBertForMaskedLM.from_pretrained(full_model1_path)\n","bert_model2 = TFBertForMaskedLM.from_pretrained(full_model2_path)\n","\n","embedding_layer1 = bert_model1.bert.embeddings\n","embedding_layer2 = bert_model2.bert.embeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"od2-Vtu8N6zY","executionInfo":{"status":"ok","timestamp":1722222406529,"user_tz":300,"elapsed":3542,"user":{"displayName":"Kenneth Lin","userId":"01443000796591967739"}},"outputId":"7af76232-eb29-4a7a-b551-c3a5620aab52"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at /content/gdrive/My Drive/Colab Notebooks/w266_final_proj/birthyear.1990_2009.lowercase_64batch_size_1000steps were not used when initializing TFBertForMaskedLM: ['encoder/layer_._1/attention/self/value/bias:0', 'encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'encoder/layer_._10/attention/self/value/kernel:0', 'encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'encoder/layer_._6/attention/self/query/kernel:0', 'encoder/layer_._0/attention/output/dense/bias:0', 'encoder/layer_._9/attention/output/dense/kernel:0', 'encoder/layer_._2/output/dense/bias:0', 'encoder/layer_._6/attention/output/LayerNorm/beta:0', 'encoder/layer_._0/attention/output/dense/kernel:0', 'encoder/layer_._2/attention/self/value/kernel:0', 'encoder/layer_._4/attention/self/query/kernel:0', 'encoder/layer_._2/attention/output/dense/kernel:0', 'predictions/transform/dense/bias:0', 'encoder/layer_._1/output/dense/kernel:0', 'encoder/layer_._1/output/LayerNorm/gamma:0', 'encoder/layer_._10/attention/output/dense/bias:0', 'encoder/layer_._9/attention/self/query/kernel:0', 'encoder/layer_._9/attention/self/key/bias:0', 'encoder/layer_._11/attention/self/query/kernel:0', 'encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'encoder/layer_._0/output/dense/bias:0', 'encoder/layer_._5/output/LayerNorm/gamma:0', 'encoder/layer_._2/attention/self/key/bias:0', 'encoder/layer_._3/output/LayerNorm/beta:0', 'encoder/layer_._1/attention/self/query/bias:0', 'encoder/layer_._3/output/LayerNorm/gamma:0', 'encoder/layer_._5/attention/self/value/kernel:0', 'encoder/layer_._4/output/LayerNorm/beta:0', 'encoder/layer_._9/attention/output/LayerNorm/beta:0', 'encoder/layer_._5/attention/output/dense/kernel:0', 'encoder/layer_._2/output/dense/kernel:0', 'encoder/layer_._10/output/dense/kernel:0', 'encoder/layer_._9/output/dense/bias:0', 'encoder/layer_._10/attention/self/query/kernel:0', 'encoder/layer_._6/attention/self/value/bias:0', 'encoder/layer_._7/intermediate/dense/kernel:0', 'encoder/layer_._2/attention/self/key/kernel:0', 'encoder/layer_._6/attention/self/key/bias:0', 'encoder/layer_._2/attention/self/query/kernel:0', 'encoder/layer_._6/attention/self/value/kernel:0', 'encoder/layer_._2/attention/self/query/bias:0', 'encoder/layer_._3/attention/output/dense/kernel:0', 'encoder/layer_._10/attention/self/query/bias:0', 'encoder/layer_._1/attention/self/key/kernel:0', 'encoder/layer_._6/attention/self/key/kernel:0', 'encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'predictions/bias:0', 'encoder/layer_._11/attention/self/value/bias:0', 'encoder/layer_._1/intermediate/dense/kernel:0', 'encoder/layer_._6/attention/self/query/bias:0', 'encoder/layer_._2/attention/output/LayerNorm/beta:0', 'encoder/layer_._11/output/LayerNorm/beta:0', 'encoder/layer_._8/attention/output/LayerNorm/beta:0', 'encoder/layer_._7/output/LayerNorm/gamma:0', 'predictions/transform/LayerNorm/beta:0', 'encoder/layer_._6/output/dense/bias:0', 'encoder/layer_._1/attention/self/value/kernel:0', 'encoder/layer_._2/output/LayerNorm/gamma:0', 'encoder/layer_._1/output/LayerNorm/beta:0', 'encoder/layer_._1/output/dense/bias:0', 'embeddings/position_embeddings/embeddings:0', 'encoder/layer_._9/output/LayerNorm/gamma:0', 'encoder/layer_._3/attention/self/key/kernel:0', 'encoder/layer_._4/attention/output/LayerNorm/beta:0', 'encoder/layer_._5/intermediate/dense/kernel:0', 'encoder/layer_._9/attention/self/value/bias:0', 'encoder/layer_._0/attention/self/value/kernel:0', 'encoder/layer_._9/attention/output/dense/bias:0', 'encoder/layer_._10/output/dense/bias:0', 'encoder/layer_._10/attention/self/key/bias:0', 'encoder/layer_._5/attention/output/dense/bias:0', 'encoder/layer_._10/output/LayerNorm/beta:0', 'encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'encoder/layer_._4/output/dense/kernel:0', 'encoder/layer_._10/intermediate/dense/bias:0', 'encoder/layer_._1/attention/output/dense/kernel:0', 'encoder/layer_._8/intermediate/dense/bias:0', 'encoder/layer_._0/attention/self/key/bias:0', 'encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'encoder/layer_._4/intermediate/dense/bias:0', 'encoder/layer_._5/attention/self/key/kernel:0', 'encoder/layer_._9/output/dense/kernel:0', 'encoder/layer_._6/output/LayerNorm/beta:0', 'encoder/layer_._8/intermediate/dense/kernel:0', 'encoder/layer_._5/attention/output/LayerNorm/beta:0', 'encoder/layer_._1/attention/self/query/kernel:0', 'encoder/layer_._11/attention/self/key/bias:0', 'encoder/layer_._2/intermediate/dense/bias:0', 'encoder/layer_._3/intermediate/dense/kernel:0', 'encoder/layer_._8/attention/output/dense/kernel:0', 'encoder/layer_._11/output/dense/bias:0', 'encoder/layer_._11/attention/output/dense/bias:0', 'encoder/layer_._8/attention/output/dense/bias:0', 'encoder/layer_._5/attention/self/key/bias:0', 'encoder/layer_._10/attention/self/key/kernel:0', 'encoder/layer_._0/output/dense/kernel:0', 'encoder/layer_._7/attention/self/key/kernel:0', 'encoder/layer_._0/intermediate/dense/kernel:0', 'encoder/layer_._0/attention/self/query/bias:0', 'encoder/layer_._3/intermediate/dense/bias:0', 'encoder/layer_._11/intermediate/dense/bias:0', 'predictions/transform/dense/kernel:0', 'encoder/layer_._9/attention/self/key/kernel:0', 'encoder/layer_._11/attention/self/value/kernel:0', 'encoder/layer_._8/attention/self/value/kernel:0', 'encoder/layer_._9/attention/self/query/bias:0', 'encoder/layer_._2/output/LayerNorm/beta:0', 'encoder/layer_._6/attention/output/dense/kernel:0', 'encoder/layer_._10/attention/output/LayerNorm/beta:0', 'encoder/layer_._3/attention/self/query/bias:0', 'encoder/layer_._10/attention/self/value/bias:0', 'encoder/layer_._11/intermediate/dense/kernel:0', 'embeddings/word_embeddings/weight:0', 'encoder/layer_._0/output/LayerNorm/gamma:0', 'encoder/layer_._3/attention/self/value/bias:0', 'encoder/layer_._10/attention/output/dense/kernel:0', 'encoder/layer_._7/output/dense/bias:0', 'encoder/layer_._3/attention/self/query/kernel:0', 'encoder/layer_._11/output/dense/kernel:0', 'encoder/layer_._3/attention/output/LayerNorm/beta:0', 'encoder/layer_._0/intermediate/dense/bias:0', 'encoder/layer_._7/output/LayerNorm/beta:0', 'encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'encoder/layer_._9/output/LayerNorm/beta:0', 'encoder/layer_._11/attention/output/LayerNorm/beta:0', 'encoder/layer_._6/output/LayerNorm/gamma:0', 'encoder/layer_._4/attention/self/value/bias:0', 'encoder/layer_._3/attention/self/value/kernel:0', 'encoder/layer_._10/output/LayerNorm/gamma:0', 'embeddings/LayerNorm/beta:0', 'encoder/layer_._1/attention/self/key/bias:0', 'encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'encoder/layer_._3/attention/output/dense/bias:0', 'encoder/layer_._8/attention/self/key/bias:0', 'encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'encoder/layer_._0/attention/output/LayerNorm/beta:0', 'encoder/layer_._6/output/dense/kernel:0', 'encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'encoder/layer_._6/intermediate/dense/kernel:0', 'encoder/layer_._4/attention/self/key/kernel:0', 'encoder/layer_._8/attention/self/query/bias:0', 'encoder/layer_._7/attention/self/query/bias:0', 'encoder/layer_._7/attention/self/query/kernel:0', 'encoder/layer_._5/output/dense/kernel:0', 'encoder/layer_._7/attention/output/LayerNorm/beta:0', 'encoder/layer_._8/attention/self/value/bias:0', 'embeddings/token_type_embeddings/embeddings:0', 'encoder/layer_._0/attention/self/query/kernel:0', 'encoder/layer_._4/output/dense/bias:0', 'encoder/layer_._1/attention/output/LayerNorm/beta:0', 'encoder/layer_._5/attention/self/value/bias:0', 'encoder/layer_._4/attention/output/dense/kernel:0', 'encoder/layer_._3/output/dense/bias:0', 'encoder/layer_._4/intermediate/dense/kernel:0', 'encoder/layer_._4/output/LayerNorm/gamma:0', 'encoder/layer_._7/attention/self/value/kernel:0', 'encoder/layer_._5/attention/self/query/bias:0', 'encoder/layer_._7/attention/self/value/bias:0', 'encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'encoder/layer_._11/output/LayerNorm/gamma:0', 'encoder/layer_._11/attention/output/dense/kernel:0', 'encoder/layer_._4/attention/self/query/bias:0', 'encoder/layer_._4/attention/self/key/bias:0', 'encoder/layer_._9/intermediate/dense/bias:0', 'encoder/layer_._2/attention/self/value/bias:0', 'encoder/layer_._7/attention/self/key/bias:0', 'encoder/layer_._9/intermediate/dense/kernel:0', 'encoder/layer_._7/attention/output/dense/kernel:0', 'encoder/layer_._4/attention/self/value/kernel:0', 'encoder/layer_._7/output/dense/kernel:0', 'encoder/layer_._0/attention/self/value/bias:0', 'encoder/layer_._8/attention/self/key/kernel:0', 'encoder/layer_._9/attention/self/value/kernel:0', 'encoder/layer_._2/intermediate/dense/kernel:0', 'encoder/layer_._4/attention/output/dense/bias:0', 'encoder/layer_._8/output/dense/bias:0', 'encoder/layer_._2/attention/output/dense/bias:0', 'encoder/layer_._6/attention/output/dense/bias:0', 'predictions/transform/LayerNorm/gamma:0', 'encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'encoder/layer_._7/attention/output/dense/bias:0', 'encoder/layer_._5/output/LayerNorm/beta:0', 'encoder/layer_._8/output/LayerNorm/gamma:0', 'embeddings/LayerNorm/gamma:0', 'encoder/layer_._6/intermediate/dense/bias:0', 'encoder/layer_._10/intermediate/dense/kernel:0', 'encoder/layer_._8/output/dense/kernel:0', 'encoder/layer_._5/attention/self/query/kernel:0', 'encoder/layer_._5/intermediate/dense/bias:0', 'encoder/layer_._0/attention/self/key/kernel:0', 'encoder/layer_._7/intermediate/dense/bias:0', 'encoder/layer_._1/intermediate/dense/bias:0', 'encoder/layer_._1/attention/output/dense/bias:0', 'encoder/layer_._0/output/LayerNorm/beta:0', 'encoder/layer_._8/output/LayerNorm/beta:0', 'encoder/layer_._8/attention/self/query/kernel:0', 'encoder/layer_._3/output/dense/kernel:0', 'encoder/layer_._11/attention/self/key/kernel:0', 'encoder/layer_._11/attention/self/query/bias:0', 'encoder/layer_._5/output/dense/bias:0', 'encoder/layer_._3/attention/self/key/bias:0']\n","- This IS expected if you are initializing TFBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFBertForMaskedLM were not initialized from the model checkpoint at /content/gdrive/My Drive/Colab Notebooks/w266_final_proj/birthyear.1990_2009.lowercase_64batch_size_1000steps and are newly initialized: ['bert/encoder/layer_._8/attention/output/dense/bias:0', 'bert/encoder/layer_._6/attention/self/value/bias:0', 'bert/encoder/layer_._8/attention/self/query/bias:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._6/output/LayerNorm/beta:0', 'bert/encoder/layer_._2/attention/self/query/bias:0', 'bert/encoder/layer_._10/attention/self/value/kernel:0', 'bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._6/attention/self/value/kernel:0', 'bert/encoder/layer_._8/attention/self/query/kernel:0', 'bert/encoder/layer_._6/intermediate/dense/bias:0', 'bert/embeddings/token_type_embeddings/weight:0', 'bert/encoder/layer_._1/attention/output/dense/bias:0', 'bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/attention/self/query/kernel:0', 'bert/encoder/layer_._7/output/dense/bias:0', 'bert/encoder/layer_._4/intermediate/dense/kernel:0', 'bert/encoder/layer_._5/intermediate/dense/bias:0', 'bert/encoder/layer_._10/attention/self/key/kernel:0', 'bert/embeddings/LayerNorm/beta:0', 'bert/encoder/layer_._4/attention/self/query/bias:0', 'bert/encoder/layer_._7/intermediate/dense/kernel:0', 'bert/encoder/layer_._8/intermediate/dense/bias:0', 'bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._0/output/dense/kernel:0', 'bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/value/kernel:0', 'bert/encoder/layer_._9/intermediate/dense/bias:0', 'bert/encoder/layer_._2/attention/self/value/kernel:0', 'bert/encoder/layer_._9/attention/self/value/kernel:0', 'bert/encoder/layer_._11/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/self/value/bias:0', 'bert/encoder/layer_._3/attention/self/query/bias:0', 'bert/encoder/layer_._9/attention/self/key/kernel:0', 'bert/encoder/layer_._7/output/LayerNorm/beta:0', 'bert/encoder/layer_._9/output/dense/bias:0', 'bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._3/attention/self/query/kernel:0', 'bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/attention/self/key/bias:0', 'bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._5/output/dense/kernel:0', 'bert/encoder/layer_._0/attention/output/dense/kernel:0', 'bert/encoder/layer_._6/intermediate/dense/kernel:0', 'bert/encoder/layer_._9/attention/output/dense/bias:0', 'bert/encoder/layer_._9/attention/self/query/kernel:0', 'bert/encoder/layer_._2/output/LayerNorm/beta:0', 'bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/attention/output/dense/kernel:0', 'bert/encoder/layer_._0/attention/output/dense/bias:0', 'bert/encoder/layer_._2/attention/self/value/bias:0', 'bert/encoder/layer_._7/attention/self/query/kernel:0', 'bert/encoder/layer_._10/attention/self/query/bias:0', 'mlm___cls/predictions/transform/dense/bias:0', 'bert/encoder/layer_._3/attention/self/key/bias:0', 'bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'bert/encoder/layer_._8/attention/self/value/bias:0', 'mlm___cls/predictions/transform/LayerNorm/gamma:0', 'bert/encoder/layer_._0/attention/self/value/bias:0', 'bert/encoder/layer_._3/attention/output/dense/kernel:0', 'bert/encoder/layer_._1/intermediate/dense/kernel:0', 'bert/encoder/layer_._9/attention/self/query/bias:0', 'bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'bert/encoder/layer_._1/output/dense/bias:0', 'bert/encoder/layer_._9/attention/output/dense/kernel:0', 'bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._0/output/dense/bias:0', 'bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/self/query/kernel:0', 'bert/encoder/layer_._1/attention/self/key/bias:0', 'bert/encoder/layer_._5/attention/self/key/bias:0', 'bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._2/output/dense/bias:0', 'bert/encoder/layer_._3/attention/output/dense/bias:0', 'bert/encoder/layer_._5/output/dense/bias:0', 'bert/encoder/layer_._6/attention/self/query/kernel:0', 'bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._4/attention/self/query/kernel:0', 'bert/encoder/layer_._4/output/dense/kernel:0', 'bert/encoder/layer_._10/attention/output/dense/bias:0', 'bert/encoder/layer_._8/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/query/kernel:0', 'bert/encoder/layer_._1/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/query/bias:0', 'bert/encoder/layer_._3/attention/self/value/kernel:0', 'bert/encoder/layer_._0/output/LayerNorm/beta:0', 'bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._6/attention/output/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/value/kernel:0', 'bert/encoder/layer_._7/attention/self/value/bias:0', 'bert/encoder/layer_._3/attention/self/key/kernel:0', 'bert/encoder/layer_._4/intermediate/dense/bias:0', 'bert/encoder/layer_._8/output/dense/bias:0', 'bert/encoder/layer_._10/attention/self/key/bias:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/output/LayerNorm/beta:0', 'bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'bert/embeddings/position_embeddings/weight:0', 'bert/encoder/layer_._1/attention/self/key/kernel:0', 'bert/encoder/layer_._8/attention/self/key/kernel:0', 'bert/encoder/layer_._10/attention/output/dense/kernel:0', 'bert/encoder/layer_._6/attention/self/query/bias:0', 'bert/encoder/layer_._7/intermediate/dense/bias:0', 'bert/encoder/layer_._11/output/dense/bias:0', 'bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'bert/encoder/layer_._5/attention/self/query/bias:0', 'bert/encoder/layer_._1/attention/self/value/bias:0', 'bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'bert/embeddings/word_embeddings/weight:0', 'bert/encoder/layer_._7/attention/self/key/bias:0', 'bert/encoder/layer_._0/intermediate/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/key/bias:0', 'bert/encoder/layer_._5/attention/self/value/bias:0', 'mlm___cls/predictions/transform/LayerNorm/beta:0', 'bert/encoder/layer_._3/output/dense/bias:0', 'bert/encoder/layer_._5/output/LayerNorm/beta:0', 'bert/encoder/layer_._5/attention/self/query/kernel:0', 'bert/encoder/layer_._6/attention/self/key/kernel:0', 'bert/encoder/layer_._1/attention/self/query/kernel:0', 'bert/encoder/layer_._9/attention/self/value/bias:0', 'mlm___cls/predictions/bias:0', 'bert/encoder/layer_._11/attention/self/value/kernel:0', 'bert/encoder/layer_._8/intermediate/dense/kernel:0', 'bert/encoder/layer_._9/intermediate/dense/kernel:0', 'mlm___cls/predictions/transform/dense/kernel:0', 'bert/encoder/layer_._10/intermediate/dense/bias:0', 'bert/encoder/layer_._4/attention/output/dense/kernel:0', 'bert/encoder/layer_._11/intermediate/dense/kernel:0', 'bert/encoder/layer_._7/attention/self/value/kernel:0', 'bert/encoder/layer_._8/attention/self/value/kernel:0', 'bert/encoder/layer_._3/attention/self/value/bias:0', 'bert/encoder/layer_._5/attention/self/value/kernel:0', 'bert/encoder/layer_._5/attention/output/dense/kernel:0', 'bert/encoder/layer_._1/attention/self/query/bias:0', 'bert/encoder/layer_._2/intermediate/dense/kernel:0', 'bert/encoder/layer_._9/attention/self/key/bias:0', 'bert/encoder/layer_._10/output/dense/kernel:0', 'bert/encoder/layer_._1/attention/self/value/kernel:0', 'bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/attention/self/query/kernel:0', 'bert/encoder/layer_._0/attention/self/key/bias:0', 'bert/encoder/layer_._5/intermediate/dense/kernel:0', 'bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._9/output/dense/kernel:0', 'bert/encoder/layer_._4/output/dense/bias:0', 'bert/encoder/layer_._1/attention/output/dense/kernel:0', 'bert/encoder/layer_._7/attention/output/dense/bias:0', 'bert/encoder/layer_._8/attention/output/dense/kernel:0', 'bert/encoder/layer_._10/intermediate/dense/kernel:0', 'bert/encoder/layer_._4/output/LayerNorm/beta:0', 'bert/encoder/layer_._3/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/output/dense/kernel:0', 'bert/encoder/layer_._6/attention/self/key/bias:0', 'bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/attention/self/key/kernel:0', 'bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._3/intermediate/dense/bias:0', 'bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'bert/encoder/layer_._6/output/dense/bias:0', 'bert/encoder/layer_._7/attention/self/key/kernel:0', 'bert/encoder/layer_._8/attention/self/key/bias:0', 'bert/encoder/layer_._1/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/key/bias:0', 'bert/encoder/layer_._3/output/LayerNorm/beta:0', 'bert/encoder/layer_._5/attention/output/dense/bias:0', 'bert/encoder/layer_._11/attention/self/key/kernel:0', 'bert/encoder/layer_._11/output/dense/kernel:0', 'bert/encoder/layer_._7/output/dense/kernel:0', 'bert/encoder/layer_._2/attention/output/dense/bias:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/intermediate/dense/bias:0', 'bert/encoder/layer_._6/attention/output/dense/bias:0', 'bert/encoder/layer_._1/intermediate/dense/bias:0', 'bert/encoder/layer_._11/attention/self/query/bias:0', 'bert/encoder/layer_._2/output/dense/kernel:0', 'bert/encoder/layer_._3/intermediate/dense/kernel:0', 'bert/encoder/layer_._8/output/dense/kernel:0', 'bert/encoder/layer_._9/output/LayerNorm/beta:0', 'bert/encoder/layer_._4/attention/self/key/kernel:0', 'bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'bert/encoder/layer_._7/attention/self/query/bias:0', 'bert/encoder/layer_._2/intermediate/dense/bias:0', 'bert/encoder/layer_._5/attention/self/key/kernel:0', 'bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/key/kernel:0', 'bert/encoder/layer_._6/output/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/value/bias:0', 'bert/encoder/layer_._4/attention/output/dense/bias:0', 'bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/attention/self/value/bias:0', 'bert/encoder/layer_._0/intermediate/dense/bias:0', 'bert/encoder/layer_._7/attention/output/dense/kernel:0', 'bert/encoder/layer_._10/output/dense/bias:0', 'bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/output/dense/bias:0', 'bert/embeddings/LayerNorm/gamma:0']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at /content/gdrive/My Drive/Colab Notebooks/w266_final_proj/birthyear.1950_1969.lowercase_64batch_size_1000steps were not used when initializing TFBertForMaskedLM: ['encoder/layer_._1/attention/self/value/bias:0', 'encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'encoder/layer_._10/attention/self/value/kernel:0', 'encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'encoder/layer_._6/attention/self/query/kernel:0', 'encoder/layer_._0/attention/output/dense/bias:0', 'encoder/layer_._9/attention/output/dense/kernel:0', 'encoder/layer_._2/output/dense/bias:0', 'encoder/layer_._6/attention/output/LayerNorm/beta:0', 'encoder/layer_._0/attention/output/dense/kernel:0', 'encoder/layer_._2/attention/self/value/kernel:0', 'encoder/layer_._4/attention/self/query/kernel:0', 'encoder/layer_._2/attention/output/dense/kernel:0', 'predictions/transform/dense/bias:0', 'encoder/layer_._1/output/dense/kernel:0', 'encoder/layer_._1/output/LayerNorm/gamma:0', 'encoder/layer_._10/attention/output/dense/bias:0', 'encoder/layer_._9/attention/self/query/kernel:0', 'encoder/layer_._9/attention/self/key/bias:0', 'encoder/layer_._11/attention/self/query/kernel:0', 'encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'encoder/layer_._0/output/dense/bias:0', 'encoder/layer_._5/output/LayerNorm/gamma:0', 'encoder/layer_._2/attention/self/key/bias:0', 'encoder/layer_._3/output/LayerNorm/beta:0', 'encoder/layer_._1/attention/self/query/bias:0', 'encoder/layer_._3/output/LayerNorm/gamma:0', 'encoder/layer_._5/attention/self/value/kernel:0', 'encoder/layer_._4/output/LayerNorm/beta:0', 'encoder/layer_._9/attention/output/LayerNorm/beta:0', 'encoder/layer_._5/attention/output/dense/kernel:0', 'encoder/layer_._2/output/dense/kernel:0', 'encoder/layer_._10/output/dense/kernel:0', 'encoder/layer_._9/output/dense/bias:0', 'encoder/layer_._10/attention/self/query/kernel:0', 'encoder/layer_._6/attention/self/value/bias:0', 'encoder/layer_._7/intermediate/dense/kernel:0', 'encoder/layer_._2/attention/self/key/kernel:0', 'encoder/layer_._6/attention/self/key/bias:0', 'encoder/layer_._2/attention/self/query/kernel:0', 'encoder/layer_._6/attention/self/value/kernel:0', 'encoder/layer_._2/attention/self/query/bias:0', 'encoder/layer_._3/attention/output/dense/kernel:0', 'encoder/layer_._10/attention/self/query/bias:0', 'encoder/layer_._1/attention/self/key/kernel:0', 'encoder/layer_._6/attention/self/key/kernel:0', 'encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'predictions/bias:0', 'encoder/layer_._11/attention/self/value/bias:0', 'encoder/layer_._1/intermediate/dense/kernel:0', 'encoder/layer_._6/attention/self/query/bias:0', 'encoder/layer_._2/attention/output/LayerNorm/beta:0', 'encoder/layer_._11/output/LayerNorm/beta:0', 'encoder/layer_._8/attention/output/LayerNorm/beta:0', 'encoder/layer_._7/output/LayerNorm/gamma:0', 'predictions/transform/LayerNorm/beta:0', 'encoder/layer_._6/output/dense/bias:0', 'encoder/layer_._1/attention/self/value/kernel:0', 'encoder/layer_._2/output/LayerNorm/gamma:0', 'encoder/layer_._1/output/LayerNorm/beta:0', 'encoder/layer_._1/output/dense/bias:0', 'embeddings/position_embeddings/embeddings:0', 'encoder/layer_._9/output/LayerNorm/gamma:0', 'encoder/layer_._3/attention/self/key/kernel:0', 'encoder/layer_._4/attention/output/LayerNorm/beta:0', 'encoder/layer_._5/intermediate/dense/kernel:0', 'encoder/layer_._9/attention/self/value/bias:0', 'encoder/layer_._0/attention/self/value/kernel:0', 'encoder/layer_._9/attention/output/dense/bias:0', 'encoder/layer_._10/output/dense/bias:0', 'encoder/layer_._10/attention/self/key/bias:0', 'encoder/layer_._5/attention/output/dense/bias:0', 'encoder/layer_._10/output/LayerNorm/beta:0', 'encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'encoder/layer_._4/output/dense/kernel:0', 'encoder/layer_._10/intermediate/dense/bias:0', 'encoder/layer_._1/attention/output/dense/kernel:0', 'encoder/layer_._8/intermediate/dense/bias:0', 'encoder/layer_._0/attention/self/key/bias:0', 'encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'encoder/layer_._4/intermediate/dense/bias:0', 'encoder/layer_._5/attention/self/key/kernel:0', 'encoder/layer_._9/output/dense/kernel:0', 'encoder/layer_._6/output/LayerNorm/beta:0', 'encoder/layer_._8/intermediate/dense/kernel:0', 'encoder/layer_._5/attention/output/LayerNorm/beta:0', 'encoder/layer_._1/attention/self/query/kernel:0', 'encoder/layer_._11/attention/self/key/bias:0', 'encoder/layer_._2/intermediate/dense/bias:0', 'encoder/layer_._3/intermediate/dense/kernel:0', 'encoder/layer_._8/attention/output/dense/kernel:0', 'encoder/layer_._11/output/dense/bias:0', 'encoder/layer_._11/attention/output/dense/bias:0', 'encoder/layer_._8/attention/output/dense/bias:0', 'encoder/layer_._5/attention/self/key/bias:0', 'encoder/layer_._10/attention/self/key/kernel:0', 'encoder/layer_._0/output/dense/kernel:0', 'encoder/layer_._7/attention/self/key/kernel:0', 'encoder/layer_._0/intermediate/dense/kernel:0', 'encoder/layer_._0/attention/self/query/bias:0', 'encoder/layer_._3/intermediate/dense/bias:0', 'encoder/layer_._11/intermediate/dense/bias:0', 'predictions/transform/dense/kernel:0', 'encoder/layer_._9/attention/self/key/kernel:0', 'encoder/layer_._11/attention/self/value/kernel:0', 'encoder/layer_._8/attention/self/value/kernel:0', 'encoder/layer_._9/attention/self/query/bias:0', 'encoder/layer_._2/output/LayerNorm/beta:0', 'encoder/layer_._6/attention/output/dense/kernel:0', 'encoder/layer_._10/attention/output/LayerNorm/beta:0', 'encoder/layer_._3/attention/self/query/bias:0', 'encoder/layer_._10/attention/self/value/bias:0', 'encoder/layer_._11/intermediate/dense/kernel:0', 'embeddings/word_embeddings/weight:0', 'encoder/layer_._0/output/LayerNorm/gamma:0', 'encoder/layer_._3/attention/self/value/bias:0', 'encoder/layer_._10/attention/output/dense/kernel:0', 'encoder/layer_._7/output/dense/bias:0', 'encoder/layer_._3/attention/self/query/kernel:0', 'encoder/layer_._11/output/dense/kernel:0', 'encoder/layer_._3/attention/output/LayerNorm/beta:0', 'encoder/layer_._0/intermediate/dense/bias:0', 'encoder/layer_._7/output/LayerNorm/beta:0', 'encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'encoder/layer_._9/output/LayerNorm/beta:0', 'encoder/layer_._11/attention/output/LayerNorm/beta:0', 'encoder/layer_._6/output/LayerNorm/gamma:0', 'encoder/layer_._4/attention/self/value/bias:0', 'encoder/layer_._3/attention/self/value/kernel:0', 'encoder/layer_._10/output/LayerNorm/gamma:0', 'embeddings/LayerNorm/beta:0', 'encoder/layer_._1/attention/self/key/bias:0', 'encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'encoder/layer_._3/attention/output/dense/bias:0', 'encoder/layer_._8/attention/self/key/bias:0', 'encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'encoder/layer_._0/attention/output/LayerNorm/beta:0', 'encoder/layer_._6/output/dense/kernel:0', 'encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'encoder/layer_._6/intermediate/dense/kernel:0', 'encoder/layer_._4/attention/self/key/kernel:0', 'encoder/layer_._8/attention/self/query/bias:0', 'encoder/layer_._7/attention/self/query/bias:0', 'encoder/layer_._7/attention/self/query/kernel:0', 'encoder/layer_._5/output/dense/kernel:0', 'encoder/layer_._7/attention/output/LayerNorm/beta:0', 'encoder/layer_._8/attention/self/value/bias:0', 'embeddings/token_type_embeddings/embeddings:0', 'encoder/layer_._0/attention/self/query/kernel:0', 'encoder/layer_._4/output/dense/bias:0', 'encoder/layer_._1/attention/output/LayerNorm/beta:0', 'encoder/layer_._5/attention/self/value/bias:0', 'encoder/layer_._4/attention/output/dense/kernel:0', 'encoder/layer_._3/output/dense/bias:0', 'encoder/layer_._4/intermediate/dense/kernel:0', 'encoder/layer_._4/output/LayerNorm/gamma:0', 'encoder/layer_._7/attention/self/value/kernel:0', 'encoder/layer_._5/attention/self/query/bias:0', 'encoder/layer_._7/attention/self/value/bias:0', 'encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'encoder/layer_._11/output/LayerNorm/gamma:0', 'encoder/layer_._11/attention/output/dense/kernel:0', 'encoder/layer_._4/attention/self/query/bias:0', 'encoder/layer_._4/attention/self/key/bias:0', 'encoder/layer_._9/intermediate/dense/bias:0', 'encoder/layer_._2/attention/self/value/bias:0', 'encoder/layer_._7/attention/self/key/bias:0', 'encoder/layer_._9/intermediate/dense/kernel:0', 'encoder/layer_._7/attention/output/dense/kernel:0', 'encoder/layer_._4/attention/self/value/kernel:0', 'encoder/layer_._7/output/dense/kernel:0', 'encoder/layer_._0/attention/self/value/bias:0', 'encoder/layer_._8/attention/self/key/kernel:0', 'encoder/layer_._9/attention/self/value/kernel:0', 'encoder/layer_._2/intermediate/dense/kernel:0', 'encoder/layer_._4/attention/output/dense/bias:0', 'encoder/layer_._8/output/dense/bias:0', 'encoder/layer_._2/attention/output/dense/bias:0', 'encoder/layer_._6/attention/output/dense/bias:0', 'predictions/transform/LayerNorm/gamma:0', 'encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'encoder/layer_._7/attention/output/dense/bias:0', 'encoder/layer_._5/output/LayerNorm/beta:0', 'encoder/layer_._8/output/LayerNorm/gamma:0', 'embeddings/LayerNorm/gamma:0', 'encoder/layer_._6/intermediate/dense/bias:0', 'encoder/layer_._10/intermediate/dense/kernel:0', 'encoder/layer_._8/output/dense/kernel:0', 'encoder/layer_._5/attention/self/query/kernel:0', 'encoder/layer_._5/intermediate/dense/bias:0', 'encoder/layer_._0/attention/self/key/kernel:0', 'encoder/layer_._7/intermediate/dense/bias:0', 'encoder/layer_._1/intermediate/dense/bias:0', 'encoder/layer_._1/attention/output/dense/bias:0', 'encoder/layer_._0/output/LayerNorm/beta:0', 'encoder/layer_._8/output/LayerNorm/beta:0', 'encoder/layer_._8/attention/self/query/kernel:0', 'encoder/layer_._3/output/dense/kernel:0', 'encoder/layer_._11/attention/self/key/kernel:0', 'encoder/layer_._11/attention/self/query/bias:0', 'encoder/layer_._5/output/dense/bias:0', 'encoder/layer_._3/attention/self/key/bias:0']\n","- This IS expected if you are initializing TFBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFBertForMaskedLM were not initialized from the model checkpoint at /content/gdrive/My Drive/Colab Notebooks/w266_final_proj/birthyear.1950_1969.lowercase_64batch_size_1000steps and are newly initialized: ['bert/encoder/layer_._8/attention/output/dense/bias:0', 'bert/encoder/layer_._6/attention/self/value/bias:0', 'bert/encoder/layer_._8/attention/self/query/bias:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._6/output/LayerNorm/beta:0', 'bert/encoder/layer_._2/attention/self/query/bias:0', 'bert/encoder/layer_._10/attention/self/value/kernel:0', 'bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._6/attention/self/value/kernel:0', 'bert/encoder/layer_._8/attention/self/query/kernel:0', 'bert/encoder/layer_._6/intermediate/dense/bias:0', 'bert/embeddings/token_type_embeddings/weight:0', 'bert/encoder/layer_._1/attention/output/dense/bias:0', 'bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/attention/self/query/kernel:0', 'bert/encoder/layer_._7/output/dense/bias:0', 'bert/encoder/layer_._4/intermediate/dense/kernel:0', 'bert/encoder/layer_._5/intermediate/dense/bias:0', 'bert/encoder/layer_._10/attention/self/key/kernel:0', 'bert/embeddings/LayerNorm/beta:0', 'bert/encoder/layer_._4/attention/self/query/bias:0', 'bert/encoder/layer_._7/intermediate/dense/kernel:0', 'bert/encoder/layer_._8/intermediate/dense/bias:0', 'bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._0/output/dense/kernel:0', 'bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/value/kernel:0', 'bert/encoder/layer_._9/intermediate/dense/bias:0', 'bert/encoder/layer_._2/attention/self/value/kernel:0', 'bert/encoder/layer_._9/attention/self/value/kernel:0', 'bert/encoder/layer_._11/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/self/value/bias:0', 'bert/encoder/layer_._3/attention/self/query/bias:0', 'bert/encoder/layer_._9/attention/self/key/kernel:0', 'bert/encoder/layer_._7/output/LayerNorm/beta:0', 'bert/encoder/layer_._9/output/dense/bias:0', 'bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._3/attention/self/query/kernel:0', 'bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/attention/self/key/bias:0', 'bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._5/output/dense/kernel:0', 'bert/encoder/layer_._0/attention/output/dense/kernel:0', 'bert/encoder/layer_._6/intermediate/dense/kernel:0', 'bert/encoder/layer_._9/attention/output/dense/bias:0', 'bert/encoder/layer_._9/attention/self/query/kernel:0', 'bert/encoder/layer_._2/output/LayerNorm/beta:0', 'bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/attention/output/dense/kernel:0', 'bert/encoder/layer_._0/attention/output/dense/bias:0', 'bert/encoder/layer_._2/attention/self/value/bias:0', 'bert/encoder/layer_._7/attention/self/query/kernel:0', 'bert/encoder/layer_._10/attention/self/query/bias:0', 'mlm___cls/predictions/transform/dense/bias:0', 'bert/encoder/layer_._3/attention/self/key/bias:0', 'bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'bert/encoder/layer_._8/attention/self/value/bias:0', 'mlm___cls/predictions/transform/LayerNorm/gamma:0', 'bert/encoder/layer_._0/attention/self/value/bias:0', 'bert/encoder/layer_._3/attention/output/dense/kernel:0', 'bert/encoder/layer_._1/intermediate/dense/kernel:0', 'bert/encoder/layer_._9/attention/self/query/bias:0', 'bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'bert/encoder/layer_._1/output/dense/bias:0', 'bert/encoder/layer_._9/attention/output/dense/kernel:0', 'bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._0/output/dense/bias:0', 'bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/self/query/kernel:0', 'bert/encoder/layer_._1/attention/self/key/bias:0', 'bert/encoder/layer_._5/attention/self/key/bias:0', 'bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._2/output/dense/bias:0', 'bert/encoder/layer_._3/attention/output/dense/bias:0', 'bert/encoder/layer_._5/output/dense/bias:0', 'bert/encoder/layer_._6/attention/self/query/kernel:0', 'bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._4/attention/self/query/kernel:0', 'bert/encoder/layer_._4/output/dense/kernel:0', 'bert/encoder/layer_._10/attention/output/dense/bias:0', 'bert/encoder/layer_._8/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/query/kernel:0', 'bert/encoder/layer_._1/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/query/bias:0', 'bert/encoder/layer_._3/attention/self/value/kernel:0', 'bert/encoder/layer_._0/output/LayerNorm/beta:0', 'bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._6/attention/output/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/value/kernel:0', 'bert/encoder/layer_._7/attention/self/value/bias:0', 'bert/encoder/layer_._3/attention/self/key/kernel:0', 'bert/encoder/layer_._4/intermediate/dense/bias:0', 'bert/encoder/layer_._8/output/dense/bias:0', 'bert/encoder/layer_._10/attention/self/key/bias:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/output/LayerNorm/beta:0', 'bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'bert/embeddings/position_embeddings/weight:0', 'bert/encoder/layer_._1/attention/self/key/kernel:0', 'bert/encoder/layer_._8/attention/self/key/kernel:0', 'bert/encoder/layer_._10/attention/output/dense/kernel:0', 'bert/encoder/layer_._6/attention/self/query/bias:0', 'bert/encoder/layer_._7/intermediate/dense/bias:0', 'bert/encoder/layer_._11/output/dense/bias:0', 'bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'bert/encoder/layer_._5/attention/self/query/bias:0', 'bert/encoder/layer_._1/attention/self/value/bias:0', 'bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'bert/embeddings/word_embeddings/weight:0', 'bert/encoder/layer_._7/attention/self/key/bias:0', 'bert/encoder/layer_._0/intermediate/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/key/bias:0', 'bert/encoder/layer_._5/attention/self/value/bias:0', 'mlm___cls/predictions/transform/LayerNorm/beta:0', 'bert/encoder/layer_._3/output/dense/bias:0', 'bert/encoder/layer_._5/output/LayerNorm/beta:0', 'bert/encoder/layer_._5/attention/self/query/kernel:0', 'bert/encoder/layer_._6/attention/self/key/kernel:0', 'bert/encoder/layer_._1/attention/self/query/kernel:0', 'bert/encoder/layer_._9/attention/self/value/bias:0', 'mlm___cls/predictions/bias:0', 'bert/encoder/layer_._11/attention/self/value/kernel:0', 'bert/encoder/layer_._8/intermediate/dense/kernel:0', 'bert/encoder/layer_._9/intermediate/dense/kernel:0', 'mlm___cls/predictions/transform/dense/kernel:0', 'bert/encoder/layer_._10/intermediate/dense/bias:0', 'bert/encoder/layer_._4/attention/output/dense/kernel:0', 'bert/encoder/layer_._11/intermediate/dense/kernel:0', 'bert/encoder/layer_._7/attention/self/value/kernel:0', 'bert/encoder/layer_._8/attention/self/value/kernel:0', 'bert/encoder/layer_._3/attention/self/value/bias:0', 'bert/encoder/layer_._5/attention/self/value/kernel:0', 'bert/encoder/layer_._5/attention/output/dense/kernel:0', 'bert/encoder/layer_._1/attention/self/query/bias:0', 'bert/encoder/layer_._2/intermediate/dense/kernel:0', 'bert/encoder/layer_._9/attention/self/key/bias:0', 'bert/encoder/layer_._10/output/dense/kernel:0', 'bert/encoder/layer_._1/attention/self/value/kernel:0', 'bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/attention/self/query/kernel:0', 'bert/encoder/layer_._0/attention/self/key/bias:0', 'bert/encoder/layer_._5/intermediate/dense/kernel:0', 'bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._9/output/dense/kernel:0', 'bert/encoder/layer_._4/output/dense/bias:0', 'bert/encoder/layer_._1/attention/output/dense/kernel:0', 'bert/encoder/layer_._7/attention/output/dense/bias:0', 'bert/encoder/layer_._8/attention/output/dense/kernel:0', 'bert/encoder/layer_._10/intermediate/dense/kernel:0', 'bert/encoder/layer_._4/output/LayerNorm/beta:0', 'bert/encoder/layer_._3/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/output/dense/kernel:0', 'bert/encoder/layer_._6/attention/self/key/bias:0', 'bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/attention/self/key/kernel:0', 'bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._3/intermediate/dense/bias:0', 'bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'bert/encoder/layer_._6/output/dense/bias:0', 'bert/encoder/layer_._7/attention/self/key/kernel:0', 'bert/encoder/layer_._8/attention/self/key/bias:0', 'bert/encoder/layer_._1/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/key/bias:0', 'bert/encoder/layer_._3/output/LayerNorm/beta:0', 'bert/encoder/layer_._5/attention/output/dense/bias:0', 'bert/encoder/layer_._11/attention/self/key/kernel:0', 'bert/encoder/layer_._11/output/dense/kernel:0', 'bert/encoder/layer_._7/output/dense/kernel:0', 'bert/encoder/layer_._2/attention/output/dense/bias:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/intermediate/dense/bias:0', 'bert/encoder/layer_._6/attention/output/dense/bias:0', 'bert/encoder/layer_._1/intermediate/dense/bias:0', 'bert/encoder/layer_._11/attention/self/query/bias:0', 'bert/encoder/layer_._2/output/dense/kernel:0', 'bert/encoder/layer_._3/intermediate/dense/kernel:0', 'bert/encoder/layer_._8/output/dense/kernel:0', 'bert/encoder/layer_._9/output/LayerNorm/beta:0', 'bert/encoder/layer_._4/attention/self/key/kernel:0', 'bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'bert/encoder/layer_._7/attention/self/query/bias:0', 'bert/encoder/layer_._2/intermediate/dense/bias:0', 'bert/encoder/layer_._5/attention/self/key/kernel:0', 'bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/key/kernel:0', 'bert/encoder/layer_._6/output/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/value/bias:0', 'bert/encoder/layer_._4/attention/output/dense/bias:0', 'bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/attention/self/value/bias:0', 'bert/encoder/layer_._0/intermediate/dense/bias:0', 'bert/encoder/layer_._7/attention/output/dense/kernel:0', 'bert/encoder/layer_._10/output/dense/bias:0', 'bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/output/dense/bias:0', 'bert/embeddings/LayerNorm/gamma:0']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["## Retrieving Vocab from each Tokenizer"],"metadata":{"id":"jwe4REPAXxZh"}},{"cell_type":"code","source":["vocab1 = tokenizer1.get_vocab()\n","vocab_ids1 = list(vocab1.values())\n","embeddings1 = [embedding_layer1(tf.constant([[token_id]]))[0][0] for token_id in vocab_ids1]\n","\n","vocab2 = tokenizer2.get_vocab()\n","vocab_ids2 = list(vocab2.values())\n","embeddings2 = [embedding_layer2(tf.constant([[token_id]]))[0][0] for token_id in vocab_ids2]"],"metadata":{"id":"vDoHCPJoUPe9","executionInfo":{"status":"ok","timestamp":1722222833906,"user_tz":300,"elapsed":427380,"user":{"displayName":"Kenneth Lin","userId":"01443000796591967739"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Comparing to Tokens from Original Paper"],"metadata":{"id":"8o1bMEVRctXZ"}},{"cell_type":"code","source":["tokens = [\"dem\", \"dam\", \"rep\", \"assist\", \"pr\", \"fr\", \"joint\", \"mega\", \"flow\", \"icymi\"]\n","k = 10\n","for token in tokens:\n","    top_k1, _ = get_k_nearest_neighbors(\n","        token,\n","        embeddings1,\n","        tokenizer1,\n","        embedding_layer1,\n","        k = k\n","    )\n","\n","    top_k2, _ = get_k_nearest_neighbors(\n","        token,\n","        embeddings2,\n","        tokenizer2,\n","        embedding_layer2,\n","        k = k\n","    )\n","\n","    print(f\"Token: {token}\")\n","    print(f\"Top {k} neighbors from tokenizer 1:\")\n","    print(top_k1)\n","    print(f\"Top {k} neighbors from tokenizer 2:\")\n","    print(top_k2)\n","    intersection = set(top_k1).intersection(set(top_k2))\n","    print(f\"Intersection: {intersection} ({len(intersection)} / {k})\")\n","    print(\"========================================\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mZyvR8JwY4ip","executionInfo":{"status":"ok","timestamp":1722223255030,"user_tz":300,"elapsed":16811,"user":{"displayName":"Kenneth Lin","userId":"01443000796591967739"}},"outputId":"4151e199-7910-4a36-96aa-93261cbeb57b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Token: dem\n","Top 10 neighbors from tokenizer 1:\n","['##u' 'slap' 'scuba' 'gardening' 'pros' 'julie' '##ssa' 'opening'\n"," 'sleeve' '👬']\n","Top 10 neighbors from tokenizer 2:\n","['##ᄑ' 'wrongs' 'muscles' 'elitist' 'tens' '##м' 'organising'\n"," 'commentator' 'citiz' 'begins']\n","Intersection: set() (0 / 10)\n","========================================\n","Token: dam\n","Top 10 neighbors from tokenizer 1:\n","['##”' 'kry' 'amazes' 'obesity' 'physical' 'bamb' 'gast' 'dissertation'\n"," 'autobiography' '📑']\n","Top 10 neighbors from tokenizer 2:\n","['after' '##ٹ' 'sandy' '##𗀟' 'betrayal' 'length' 'indep' 'apprentice'\n"," '##fb' 'pathfinder']\n","Intersection: set() (0 / 10)\n","========================================\n","Token: rep\n","Top 10 neighbors from tokenizer 1:\n","['wisco' 'dube' 'thinking' 'farmer' 'cudi' 'shamed' 'wilf' 'skydiving'\n"," 'ming' 'mcgreg']\n","Top 10 neighbors from tokenizer 2:\n","['playful' '##orting' 'bax' '##do' 'curios' '##style' '##maid' 'ocean'\n"," 'supermarket' 'millen']\n","Intersection: set() (0 / 10)\n","========================================\n","Token: assist\n","Top 10 neighbors from tokenizer 1:\n","['##iverse' '##💫' 'gwen' 'treating' 'chopped' 'strugg' '##otch'\n"," 'relentless' 'startin' 'ustream']\n","Top 10 neighbors from tokenizer 2:\n","['##lon' 'emb' 'ally' 'alaska' '##宿' 'hangout' '##afi' 'cll' 'airplanes'\n"," '##家']\n","Intersection: set() (0 / 10)\n","========================================\n","Token: pr\n","Top 10 neighbors from tokenizer 1:\n","['pess' 'kris' 'banking' 'stylist' 'turn' '##⚔' 'editorial' 'invit'\n"," 'togetherness' '##urers']\n","Top 10 neighbors from tokenizer 2:\n","['individ' '##oust' 'sentiment' 'awards' 'conservation' 'tries' '##right'\n"," 'override' '##res' 'pizza']\n","Intersection: set() (0 / 10)\n","========================================\n","Token: fr\n","Top 10 neighbors from tokenizer 1:\n","['mom' 'workah' 'exit' 'box' 'bot' 'khabib' 'heath' 'lust' 'lanes'\n"," 'hardest']\n","Top 10 neighbors from tokenizer 2:\n","['lumin' '##ecd' 'landlord' 'projects' 'clayton' 'enshr' 'wentworth'\n"," 'nicholson' '##iko' 'cho']\n","Intersection: set() (0 / 10)\n","========================================\n","Token: joint\n","Top 10 neighbors from tokenizer 1:\n","['hidden' 'repeal' 'gardening' 'forsure' 'heck' 'leo' 'visits' 'jud'\n"," '##oup' 'gl']\n","Top 10 neighbors from tokenizer 2:\n","['various' 'cuis' 'nigeria' 'convert' 'centenary' '🍝' '🥉' 'uncanny' 'meth'\n"," 'ally']\n","Intersection: set() (0 / 10)\n","========================================\n","Token: mega\n","Top 10 neighbors from tokenizer 1:\n","['sleeve' 'try' 'bayern' 'arranged' 'ughhh' '##aka' 'inshallah' 'probly'\n"," 'room' '🐾']\n","Top 10 neighbors from tokenizer 2:\n","['guarantee' 'dwp' 'peterborough' 'freeing' 'cdns' '##finder' '##chio'\n"," 'stripping' '的' 'belling']\n","Intersection: set() (0 / 10)\n","========================================\n","Token: flow\n","Top 10 neighbors from tokenizer 1:\n","['dolla' '##tie' 'crust' 'rd' 'thirt' 'knowled' '##team' 'cubs' 'rg'\n"," 'prius']\n","Top 10 neighbors from tokenizer 2:\n","['##force' 'anxious' 'nightmar' '##rical' 'cupcake' 'aims' '𝚗' 'equality'\n"," 'couples' '𝐢']\n","Intersection: set() (0 / 10)\n","========================================\n","Token: icymi\n","Top 10 neighbors from tokenizer 1:\n","['belongs' 'kyle' '🚔' 'dollars' 'kry' 'consider' 'composure' 'addison'\n"," 'procla' 'subscription']\n","Top 10 neighbors from tokenizer 2:\n","['nine' 'whenever' 'bedroom' 'play' 'atrocities' 'victoria' 'manh'\n"," 'expansion' 'contains' 'celebs']\n","Intersection: set() (0 / 10)\n","========================================\n"]}]},{"cell_type":"code","source":["get_k_nearest_neighbors(\n","    \"dem\",\n","    embeddings1,\n","    tokenizer1,\n","    embedding_layer1,\n","    k = 10\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":740},"id":"N6PeYHsefWhy","executionInfo":{"status":"error","timestamp":1722223001524,"user_tz":300,"elapsed":358,"user":{"displayName":"Kenneth Lin","userId":"01443000796591967739"}},"outputId":"103f8a36-13ee-4e80-b76d-df5c0acefff2"},"execution_count":12,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Input vector should be 1-D.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-272f852e22c4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m get_k_nearest_neighbors(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"dem\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0membeddings1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtokenizer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0membedding_layer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-9d3c79dec5b0>\u001b[0m in \u001b[0;36mget_k_nearest_neighbors\u001b[0;34m(token, embeddings, tokenizer, embedding_layer, k)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mdists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# don't consider when getting nearest neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mdists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# sort by cosine distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;31m# cosine distance is also referred to as 'uncentered correlation',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;31m#   or 'reflective correlation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \"\"\"\n\u001b[1;32m    625\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36m_validate_vector\u001b[0;34m(u, dtype)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input vector should be 1-D.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input vector should be 1-D."]}]},{"cell_type":"code","source":[],"metadata":{"id":"cdBdK0j1epzu"},"execution_count":null,"outputs":[]}]}